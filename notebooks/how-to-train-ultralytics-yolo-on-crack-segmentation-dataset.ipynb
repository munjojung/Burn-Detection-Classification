{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [中文](https://docs.ultralytics.com/zh/) | [한국어](https://docs.ultralytics.com/ko/) | [日本語](https://docs.ultralytics.com/ja/) | [Русский](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Français](https://docs.ultralytics.com/fr/) | [Español](https://docs.ultralytics.com/es/) | [Português](https://docs.ultralytics.com/pt/) | [Türkçe](https://docs.ultralytics.com/tr/) | [Tiếng Việt](https://docs.ultralytics.com/vi/) | [العربية](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-crack-segmentation-dataset.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Crack segmentation with Ultralytics YOLO11 🚀 notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crack Segmentation using Ultralytics YOLO11\n",
        "\n",
        "This notebook acts as a starting point for training the YOLO11 model using the [crack segmentation dataset](https://docs.ultralytics.com/datasets/segment/crack-seg/)."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Structure\n",
        "\n",
        "The division of data within the Crack Segmentation Dataset is outlined as follows:\n",
        "\n",
        "- **Training set**: Consists of 3717 images with corresponding annotations.\n",
        "\n",
        "- **Testing set**: Comprises 112 images along with their respective annotations.\n",
        "\n",
        "- **Validation set**: Includes 200 images with their corresponding annotations."
      ],
      "metadata": {
        "id": "xypoYW_oYZAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "\n",
        "Crack segmentation finds practical applications in infrastructure maintenance, aiding in the identification and assessment of structural damage. It also plays a crucial role in enhancing road safety by enabling automated systems to detect and address pavement cracks for timely repairs.\n"
      ],
      "metadata": {
        "id": "R4SICbq5Yalg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 기본설치 및 경로설정 import 추가\n",
        "# 1. 기본설치 및 경로설정 import 추가\n",
        "!pip install -q scipy scikit-learn tensorboard\n",
        "\n",
        "# 2. 필요 모듈 임포트\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# 3. 압축 파일 업로드\n",
        "print(\"▶️ 압축 파일을 선택하세요 (.zip)\")\n",
        "uploaded = files.upload()\n",
        "zip_filename = next(iter(uploaded))\n",
        "print(f\"✅ 업로드 완료: {zip_filename}\")\n",
        "\n",
        "# 4. 압축 해제\n",
        "extract_root = '.'\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_root)\n",
        "print(f\"✅ 압축 해제 완료: '{extract_root}'에 내용이 풀렸습니다\")\n",
        "\n",
        "# 5. CrackForest-dataset 폴더명 정리\n",
        "target_dir = \"CrackForest-dataset\"\n",
        "src_dir = None\n",
        "\n",
        "for item in os.listdir(extract_root):\n",
        "    if item.startswith(\"CrackForest\") and os.path.isdir(item) and item != target_dir:\n",
        "        src_dir = item\n",
        "        break\n",
        "\n",
        "if src_dir:\n",
        "    if os.path.exists(target_dir):\n",
        "        print(f\"기존 '{target_dir}' 폴더가 이미 존재합니다. 삭제 후 이름 변경을 진행합니다.\")\n",
        "        shutil.rmtree(target_dir)\n",
        "    os.rename(src_dir, target_dir)\n",
        "    print(f\"📁 폴더 이름을 '{src_dir}' ➜ '{target_dir}' 으로 변경했습니다.\")\n",
        "else:\n",
        "    print(f\"변경할 폴더가 없거나 이미 '{target_dir}' 폴더가 존재합니다.\")\n",
        "\n",
        "# 6. 데이터셋 경로 설정 및 검증\n",
        "dataset_dir = os.path.join(extract_root, target_dir)\n",
        "if not os.path.exists(dataset_dir):\n",
        "    raise FileNotFoundError(f\"❌ '{target_dir}' 폴더가 존재하지 않습니다. 압축 구조를 확인해 주세요.\")\n",
        "\n",
        "img_dir = os.path.join(dataset_dir, 'image')\n",
        "gt_dir = os.path.join(dataset_dir, 'groundTruth')\n",
        "seg_dir = os.path.join(dataset_dir, 'seg')\n",
        "\n",
        "for subdir, name in zip([img_dir, gt_dir, seg_dir], ['image', 'groundTruth', 'seg']):\n",
        "    if not os.path.exists(subdir):\n",
        "        raise FileNotFoundError(f\"❌ '{name}/' 폴더가 '{dataset_dir}' 내에 없습니다. 압축 구조를 확인해 주세요.\")\n",
        "\n",
        "# 7. 출력 디렉토리 생성\n",
        "os.makedirs('runs', exist_ok=True)\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# 8. 경로 출력\n",
        "print(f\"✅ 데이터셋 루트: {dataset_dir}\")\n",
        "print(f\"📁 이미지 폴더: {img_dir}\")\n",
        "print(f\"📁 마스크 폴더: {gt_dir}\")\n",
        "print(f\"📁 Segmentation 폴더: {seg_dir}\")\n",
        "\n",
        "# 9. 이미지 및 .mat 파일 경로 수집 (확장자 자동 감지)\n",
        "supported_img_exts = ['png', 'jpg', 'jpeg', 'bmp', 'tif', 'tiff']\n",
        "img_paths = []\n",
        "for ext in supported_img_exts:\n",
        "    img_paths.extend(glob.glob(os.path.join(img_dir, f\"*.{ext}\")))\n",
        "img_paths = sorted(img_paths)\n",
        "mat_paths = sorted(glob.glob(os.path.join(gt_dir, \"*.mat\")))\n",
        "\n",
        "# 🔍 디버깅 로그\n",
        "print(f\"\\n✅ 이미지 디렉토리 경로: {img_dir}\")\n",
        "print(f\"🖼️ 감지된 이미지 수: {len(img_paths)}\")\n",
        "if len(img_paths) > 0:\n",
        "    print(\"✅ 이미지 샘플:\", img_paths[:3])\n",
        "else:\n",
        "    print(\"⚠️ 지원되는 이미지 확장자로 된 파일이 없습니다. 실제 확장자 확인 필요\")\n",
        "print(f\"📐 감지된 GroundTruth 수: {len(mat_paths)}\")\n",
        "\n",
        "# 10. 이미지와 마스크 이름 기준으로 공통 매칭\n",
        "img_names = set([os.path.splitext(os.path.basename(p))[0] for p in img_paths])\n",
        "mat_names = set([os.path.splitext(os.path.basename(p))[0] for p in mat_paths])\n",
        "\n",
        "common_keys = sorted(img_names & mat_names)\n",
        "img_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in img_paths}\n",
        "mat_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in mat_paths}\n",
        "\n",
        "img_paths_matched = [img_dict[k] for k in common_keys]\n",
        "mat_paths_matched = [mat_dict[k] for k in common_keys]\n",
        "\n",
        "# 샘플 라벨 (예: 모두 0으로 설정)\n",
        "labels = [0] * len(common_keys)\n",
        "\n",
        "print(f\"\\n✅ 매칭된 이미지 수: {len(img_paths_matched)}\")\n",
        "print(f\"✅ 매칭된 마스크 수: {len(mat_paths_matched)}\")\n",
        "print(f\"🧷 공통된 파일 prefix 예시: {common_keys[:3]}\")\n",
        "\n",
        "# 11. Train/Validation 분리 (필요 시)\n",
        "if len(img_paths_matched) == 0:\n",
        "    raise ValueError(\"❌ 이미지와 GroundTruth가 매칭되지 않았습니다. 파일 이름을 확인하세요.\")\n",
        "\n",
        "tr = list(range(0, int(0.8 * len(img_paths_matched))))\n",
        "va = list(range(int(0.8 * len(img_paths_matched)), len(img_paths_matched)))\n",
        "\n",
        "print(f\"\\n🧪 Train indices: {min(tr)} ~ {max(tr)}\")\n",
        "print(f\"🧪 Validation indices: {min(va)} ~ {max(va)}\")\n",
        "\n",
        "# 12. 내부 폴더 구조 출력\n",
        "print(\"\\n📂 'CrackForest-dataset' 폴더 내부 구조:\")\n",
        "for root, dirs, files in os.walk(dataset_dir):\n",
        "    level = root.replace(dataset_dir, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{subindent}{f}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... 외 {len(files)-5}개 더\")\n"
      ],
      "metadata": {
        "id": "RMD0OqCyqjlw",
        "outputId": "a2fae57c-bf1c-45ca-d5f3-6225722d0659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ 압축 파일을 선택하세요 (.zip)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a6a23b1-54e8-4ec9-8d9d-5f9e7ab12fc6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a6a23b1-54e8-4ec9-8d9d-5f9e7ab12fc6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CrackForest-dataset-master.zip to CrackForest-dataset-master.zip\n",
            "✅ 업로드 완료: CrackForest-dataset-master.zip\n",
            "✅ 압축 해제 완료: '.'에 내용이 풀렸습니다\n",
            "📁 폴더 이름을 'CrackForest-dataset-master' ➜ 'CrackForest-dataset' 으로 변경했습니다.\n",
            "✅ 데이터셋 루트: ./CrackForest-dataset\n",
            "📁 이미지 폴더: ./CrackForest-dataset/image\n",
            "📁 마스크 폴더: ./CrackForest-dataset/groundTruth\n",
            "📁 Segmentation 폴더: ./CrackForest-dataset/seg\n",
            "\n",
            "✅ 이미지 디렉토리 경로: ./CrackForest-dataset/image\n",
            "🖼️ 감지된 이미지 수: 155\n",
            "✅ 이미지 샘플: ['./CrackForest-dataset/image/001.jpg', './CrackForest-dataset/image/002.jpg', './CrackForest-dataset/image/003.jpg']\n",
            "📐 감지된 GroundTruth 수: 118\n",
            "\n",
            "✅ 매칭된 이미지 수: 118\n",
            "✅ 매칭된 마스크 수: 118\n",
            "🧷 공통된 파일 prefix 예시: ['001', '002', '003']\n",
            "\n",
            "🧪 Train indices: 0 ~ 93\n",
            "🧪 Validation indices: 94 ~ 117\n",
            "\n",
            "📂 'CrackForest-dataset' 폴더 내부 구조:\n",
            "CrackForest-dataset/\n",
            "  README.md\n",
            "  seg/\n",
            "    047.seg\n",
            "    010.seg\n",
            "    114.seg\n",
            "    086.seg\n",
            "    103.seg\n",
            "    ... 외 113개 더\n",
            "  groundTruth/\n",
            "    090.mat\n",
            "    023.mat\n",
            "    075.mat\n",
            "    012.mat\n",
            "    071.mat\n",
            "    ... 외 113개 더\n",
            "  image/\n",
            "    324.jpg\n",
            "    046.jpg\n",
            "    204.jpg\n",
            "    091.jpg\n",
            "    018.jpg\n",
            "    ... 외 151개 더\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1-1 아래를 실행해야 훈련셀이 실됨\n",
        "#데이터셋 경로설정\n",
        "\n",
        "!pip install -q scipy scikit-learn tensorboard\n",
        "\n",
        "import os, random, zipfile, urllib.request\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# 경로 설정\n",
        "root = '/content/CrackForest-dataset'\n",
        "img_dir = os.path.join(root, 'image')\n",
        "gt_dir = os.path.join(root, 'groundTruth')\n",
        "os.makedirs('runs', exist_ok=True)\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# 데이터셋 다운로드\n",
        "if not os.path.exists(root):\n",
        "    url = 'https://www.dropbox.com/s/06e4r7dk6n31xgk/CrackForest-dataset.zip?dl=1'\n",
        "    zip_path = '/content/CrackForest.zip'\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "M94XFCGirOfQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 시드 및 디바이스 설정\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용 중인 디바이스: {device}\")\n"
      ],
      "metadata": {
        "id": "BjUp43YrrW24",
        "outputId": "a5c32871-fb3d-4955-cab2-45405e25b2c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 중인 디바이스: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 파일 리스트 필터링\n",
        "def get_file_num(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "all_imgs = sorted(os.listdir(img_dir))\n",
        "all_mats = sorted(os.listdir(gt_dir))\n",
        "mat_nums = set(get_file_num(f) for f in all_mats)\n",
        "\n",
        "filtered_imgs = [f for f in all_imgs if get_file_num(f) in mat_nums]\n",
        "filtered_mats = [f for f in all_mats if get_file_num(f) in [get_file_num(i) for i in filtered_imgs]]\n",
        "\n",
        "img_paths = [os.path.join(img_dir, f) for f in filtered_imgs]\n",
        "mat_paths = [os.path.join(gt_dir, f) for f in filtered_mats]\n",
        "labels = [1] * len(img_paths)\n",
        "\n",
        "print(f\"전체 이미지 수: {len(all_imgs)}\")\n",
        "print(f\"groundTruth .mat 파일 수: {len(all_mats)}\")\n",
        "print(f\"필터링된 이미지 수: {len(img_paths)}\")\n"
      ],
      "metadata": {
        "id": "9G0fDQxore6m",
        "outputId": "4469e13a-221a-4663-a6f2-b84ff2a69501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 이미지 수: 156\n",
            "groundTruth .mat 파일 수: 118\n",
            "필터링된 이미지 수: 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 CrackDataset 클래스 정의\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from torchvision import transforms\n",
        "\n",
        "class CrackDataset(Dataset):\n",
        "    def __init__(self, image_paths, mat_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mat_paths = mat_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "\n",
        "        try:\n",
        "            mat = scipy.io.loadmat(self.mat_paths[idx])\n",
        "            gt = mat.get(\"groundTruth\")\n",
        "\n",
        "            if gt is None:\n",
        "                raise ValueError(\"groundTruth 키가 없음\")\n",
        "\n",
        "            # (1,1) 구조체 배열에서 Boundaries 추출\n",
        "            boundaries_obj_array = gt[0, 0]['Boundaries']  # (1,) object array\n",
        "            mask_array = np.array(boundaries_obj_array[0])  # 실제 (H,W) numpy 배열\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Mask 추출 오류 - {self.mat_paths[idx]}: {e}\")\n",
        "\n",
        "        # 마스크 후처리\n",
        "        mask = Image.fromarray((mask_array > 0.5).astype(np.uint8) * 255)\n",
        "\n",
        "        # 이미지 및 마스크 리사이즈\n",
        "        image = image.resize((64, 64))\n",
        "        mask = mask.resize((64, 64))\n",
        "\n",
        "        # Tensor 변환\n",
        "        image = self.transform(image) if self.transform else transforms.ToTensor()(image)\n",
        "        mask = transforms.ToTensor()(mask)  # → [0,1] 범위 float tensor\n",
        "\n",
        "        #return image, (mask > 0.5).float()\n",
        "        return image, mask  # threshold 적용 X\n"
      ],
      "metadata": {
        "id": "SsE7Cqbcrh0V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 모델정의 UNet + CBAM (Channel & Spatial Attention)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=8):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        return self.sigmoid(avg_out + max_out) * x\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
        "        return self.sigmoid(self.conv(x_cat)) * x\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super().__init__()\n",
        "        self.channel_attention = ChannelAttention(in_planes)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "#격자무늬 해결중\n",
        "class UNetWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        # 인코더\n",
        "        self.enc1 = nn.Sequential(conv_block(3, 64), CBAM(64))\n",
        "        self.enc2 = nn.Sequential(conv_block(64, 128), CBAM(128))\n",
        "        self.enc3 = nn.Sequential(conv_block(128, 256), CBAM(256))\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.mid = conv_block(256, 512)\n",
        "\n",
        "        # 업샘플링: ConvTranspose → Upsample + Conv2d\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "            nn.Conv2d(512, 256, kernel_size=1)\n",
        "        )\n",
        "        self.dec2 = conv_block(512, 256)\n",
        "\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "            nn.Conv2d(256, 128, kernel_size=1)\n",
        "        )\n",
        "        self.dec1 = conv_block(256, 128)\n",
        "\n",
        "        # 출력 레이어\n",
        "        self.final = nn.Conv2d(128, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)                   # (B, 64, 64, 64)\n",
        "        e2 = self.enc2(self.pool(e1))      # (B, 128, 32, 32)\n",
        "        e3 = self.enc3(self.pool(e2))      # (B, 256, 16, 16)\n",
        "        m = self.mid(self.pool(e3))        # (B, 512, 8, 8)\n",
        "\n",
        "        d2 = self.up2(m)                   # (B, 256, 16, 16)\n",
        "        d2 = self.dec2(torch.cat([d2, e3], dim=1))  # (B, 256, 16, 16)\n",
        "\n",
        "        d1 = self.up1(d2)                  # (B, 128, 32, 32)\n",
        "        d1 = self.dec1(torch.cat([d1, e2], dim=1))  # (B, 128, 32, 32)\n",
        "\n",
        "        #out = torch.sigmoid(self.final(d1))  # (B, 1, 32, 32)\n",
        "        #BCEDiceLoss와 모델 추론 시점에 다시 sigmoid를 중복호출 제거\n",
        "        out = self.final(d1)\n",
        "\n",
        "        # 최종적으로 입력 크기(64x64)에 맞춰보정\n",
        "        #데이터셋에서 resize를 먼저 했기 때문에 모델 출력과 Ground Truth는 이미 같은 크기 그냥둬도 무방\n",
        "        #이 경우 F.interpolate(..., size=(64,64))는 중복일 수 있습니다\n",
        "        return F.interpolate(out, size=(64, 64), mode='bilinear', align_corners=False)"
      ],
      "metadata": {
        "id": "0l3aAwpMrulW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 손실함수 및 메트릭\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def forward(self, inputs, targets, smooth=1e-6):\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()\n",
        "        return 1 - (2 * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCELoss()\n",
        "        self.dice = DiceLoss()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs = torch.sigmoid(inputs)  #모델 출력은 로짓(logits)이고 확률로 변환\n",
        "        return self.bce(inputs, targets) + self.dice(inputs, targets)\n",
        "\n",
        "class IoUMetric:\n",
        "    def __call__(self, preds, masks):\n",
        "        preds = (preds > 0.5).float()\n",
        "        masks = masks.float()\n",
        "        intersection = (preds * masks).sum((1, 2, 3))\n",
        "        union = (preds + masks - preds * masks).sum((1, 2, 3))\n",
        "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "        return iou.mean().item()\n"
      ],
      "metadata": {
        "id": "TA_HNa-0r8e1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 기본 Transform 설정정\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "TyjASzHAuCOW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 K-Fold 학습 및 평가 루프 함수 정의\n",
        "#train_and_evaluate()\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def train_and_evaluate(img_paths, mat_paths, labels, num_epochs=20, batch_size=32, learning_rate=1e-3, k_folds=5):\n",
        "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "    criterion = BCEDiceLoss()\n",
        "    metric_fn = IoUMetric()\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(img_paths, labels)):\n",
        "        print(f\"\\n🔁 Fold {fold + 1}/{k_folds}\")\n",
        "        writer = SummaryWriter(log_dir=f\"runs/fold_{fold+1}\")\n",
        "\n",
        "        train_dataset = CrackDataset([img_paths[i] for i in train_idx],\n",
        "                                     [mat_paths[i] for i in train_idx],\n",
        "                                     transform=transform)\n",
        "        val_dataset = CrackDataset([img_paths[i] for i in val_idx],\n",
        "                                   [mat_paths[i] for i in val_idx],\n",
        "                                   transform=transform)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        model = UNetWithAttention().to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        best_iou = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            for batch_idx, (images, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")):\n",
        "            #for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                preds = model(images)\n",
        "                loss = criterion(preds, masks)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                # 🔍 여기서 예측 마스크 통계 확인 (첫 배치만)\n",
        "                #if batch_idx % 10 == 0:  #정해진 간격마다 출력\n",
        "                #if batch_idx == 0:  #매 에폭 첫 배치만 출력\n",
        "                #if batch_idx == 0 and epoch == 0:\n",
        "                if batch_idx == 0 and epoch % 5 == 0:  #학습진행상태에 따른 변화확인\n",
        "                    print(f\"\\n🔍 Epoch {epoch+1}, Batch {batch_idx+1}\")\n",
        "                    print(\"  Predicted mask stats:\")\n",
        "                    print(\"    Min: \", preds.min().item())\n",
        "                    print(\"    Max: \", preds.max().item())\n",
        "                    print(\"    Mean:\", preds.mean().item())\n",
        "\n",
        "            train_loss /= len(train_loader)\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            iou_score = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
        "                    images, masks = images.to(device), masks.to(device)\n",
        "                    preds = model(images)\n",
        "                    loss = criterion(preds, masks)\n",
        "                    val_loss += loss.item()\n",
        "                    iou_score += metric_fn(preds, masks)\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            iou_score /= len(val_loader)\n",
        "\n",
        "            print(f\"[Fold {fold+1}] Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | IoU: {iou_score:.4f}\")\n",
        "            writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n",
        "            writer.add_scalar(\"IoU\", iou_score, epoch)\n",
        "\n",
        "            # 모델 저장\n",
        "            if iou_score > best_iou:\n",
        "                best_iou = iou_score\n",
        "                model_path = f\"saved_models/best_model_fold_{fold+1}.pth\"\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(f\"✅ Best model saved to {model_path} (IoU={best_iou:.4f})\")\n",
        "\n",
        "        writer.close()\n"
      ],
      "metadata": {
        "id": "cXTIjJXQuYvN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 9 추론 및 시각화 함수 2D로 추출로 수정 코드\n",
        "#segmentation 추가\n",
        "#자동 vmin/max + contrast 스케일링 포함\n",
        "def predict_and_visualize(model_path, img_path, mat_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import scipy.io\n",
        "    from torchvision import transforms\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # 이미지 로드 및 전처리\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    input_tensor = transform(img).unsqueeze(0)  # (1, 3, 64, 64)\n",
        "\n",
        "    # 모델 로드\n",
        "    model = UNetWithAttention()  # 사용 중인 모델 클래스명에 맞게 수정\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
        "    model.eval()\n",
        "\n",
        "    # 예측 (logits → 확률 → numpy)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_mask = torch.sigmoid(output).squeeze().numpy()\n",
        "\n",
        "    # .mat 파일에서 GT 추출\n",
        "    mat = scipy.io.loadmat(mat_path)\n",
        "    gt_struct = mat[\"groundTruth\"][0, 0]\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = gt_struct[\"Boundaries\"]\n",
        "    if isinstance(boundaries, np.ndarray) and boundaries.dtype == object:\n",
        "        boundary_mask = boundaries[0, 0]\n",
        "    else:\n",
        "        boundary_mask = boundaries\n",
        "    if isinstance(boundary_mask, np.ndarray) and boundary_mask.dtype == object:\n",
        "        boundary_mask = boundary_mask[0]\n",
        "\n",
        "    if not isinstance(boundary_mask, np.ndarray) or boundary_mask.ndim != 2:\n",
        "        raise ValueError(f\"Invalid boundary mask shape: {boundary_mask.shape if isinstance(boundary_mask, np.ndarray) else type(boundary_mask)}\")\n",
        "\n",
        "    # Segmentation\n",
        "    segmentation = gt_struct[\"Segmentation\"]\n",
        "    if isinstance(segmentation, np.ndarray) and segmentation.dtype == object:\n",
        "        seg_mask = segmentation[0, 0]\n",
        "    else:\n",
        "        seg_mask = segmentation\n",
        "    if isinstance(seg_mask, np.ndarray) and seg_mask.dtype == object:\n",
        "        seg_mask = seg_mask[0]\n",
        "\n",
        "    if not isinstance(seg_mask, np.ndarray) or seg_mask.ndim != 2:\n",
        "        raise ValueError(f\"Invalid segmentation mask shape: {seg_mask.shape if isinstance(seg_mask, np.ndarray) else type(seg_mask)}\")\n",
        "\n",
        "    # GT 마스크 리사이즈\n",
        "    boundary_resized = Image.fromarray((boundary_mask * 255).astype(np.uint8)).resize((64, 64))\n",
        "    seg_resized = Image.fromarray((seg_mask * 255).astype(np.uint8)).resize((64, 64))\n",
        "    boundary_resized = np.array(boundary_resized) / 255.0\n",
        "    seg_resized = np.array(seg_resized) / 255.0\n",
        "\n",
        "    # Binary threshold for prediction Thresholding (선택적 추가)\n",
        "    pred_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    # 예측 마스크 contrast 조정용 스케일링 (선택사항)\n",
        "    contrast_scale = 20\n",
        "\n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(boundary_resized, cmap=\"gray\")\n",
        "    axes[1].set_title(\"Ground Truth (Boundary)\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    axes[2].imshow(seg_resized, cmap=\"gray\")\n",
        "    axes[2].set_title(\"Ground Truth (Segmentation)\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    #axes[3].imshow(pred_mask, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    #axes[3].set_title(\"Predicted (Prob)\")\n",
        "    #axes[3].axis(\"off\")\n",
        "\n",
        "    axes[3].imshow(pred_mask * contrast_scale, cmap=\"gray\")\n",
        "    axes[3].set_title(\"Predicted (Prob x {})\".format(contrast_scale))\n",
        "    axes[3].axis(\"off\")\n",
        "\n",
        "    axes[4].imshow(pred_binary, cmap=\"gray\")\n",
        "    axes[4].set_title(\"Predicted (Binary > 0.5)\")\n",
        "    axes[4].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iZrDQVIyubll"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 최종버전 학습 실행 epoch 40\n",
        "train_and_evaluate(img_paths_matched, mat_paths_matched, labels, num_epochs=40, batch_size=32, learning_rate=1e-3, k_folds=5)\n",
        "\n",
        "# 추론 예시 (학습 후 사용)\n",
        "predict_and_visualize(\"saved_models/best_model_fold_1.pth\", img_paths_matched[0], mat_paths_matched[0])\n"
      ],
      "metadata": {
        "id": "_TfLfRTPuepe",
        "outputId": "360415cf-06d2-44d1-80b0-65b239af4d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Train]:  33%|███▎      | 1/3 [00:03<00:06,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 1, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -1.0045570135116577\n",
            "    Max:  3.224926710128784\n",
            "    Mean: 0.03939331695437431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Train]: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]\n",
            "Epoch 1/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 1 | Train Loss: 1.7313 | Val Loss: 1.7561 | IoU: 1.0000\n",
            "✅ Best model saved to saved_models/best_model_fold_1.pth (IoU=1.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  3.49it/s]\n",
            "Epoch 2/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 2 | Train Loss: 1.5106 | Val Loss: 1.7761 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  3.72it/s]\n",
            "Epoch 3/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 3 | Train Loss: 1.3887 | Val Loss: 1.7070 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.06it/s]\n",
            "Epoch 4/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 4 | Train Loss: 1.2949 | Val Loss: 1.5989 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.96it/s]\n",
            "Epoch 5/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 5 | Train Loss: 1.2604 | Val Loss: 1.4574 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 6, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.180427074432373\n",
            "    Max:  -0.4370596408843994\n",
            "    Mean: -1.3873008489608765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 6 | Train Loss: 1.2244 | Val Loss: 1.3850 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.37it/s]\n",
            "Epoch 7/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 7 | Train Loss: 1.1968 | Val Loss: 1.3465 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.95it/s]\n",
            "Epoch 8/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 8 | Train Loss: 1.1708 | Val Loss: 1.3105 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.33it/s]\n",
            "Epoch 9/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 9 | Train Loss: 1.1608 | Val Loss: 1.2761 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.36it/s]\n",
            "Epoch 10/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 10 | Train Loss: 1.1397 | Val Loss: 1.2473 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 11, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.689789295196533\n",
            "    Max:  -0.5752020478248596\n",
            "    Mean: -1.982884168624878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 11 | Train Loss: 1.1238 | Val Loss: 1.2221 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.25it/s]\n",
            "Epoch 12/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 12 | Train Loss: 1.1087 | Val Loss: 1.2018 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.31it/s]\n",
            "Epoch 13/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 13 | Train Loss: 1.0974 | Val Loss: 1.1765 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.19it/s]\n",
            "Epoch 14/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 14 | Train Loss: 1.0847 | Val Loss: 1.1460 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  3.80it/s]\n",
            "Epoch 15/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 15 | Train Loss: 1.0783 | Val Loss: 1.1255 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Train]:  67%|██████▋   | 2/3 [00:00<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 16, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.558109760284424\n",
            "    Max:  -1.1151328086853027\n",
            "    Mean: -2.5579943656921387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.29it/s]\n",
            "Epoch 16/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 16 | Train Loss: 1.0731 | Val Loss: 1.1135 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.98it/s]\n",
            "Epoch 17/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 17 | Train Loss: 1.0639 | Val Loss: 1.1020 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.04it/s]\n",
            "Epoch 18/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 18 | Train Loss: 1.0611 | Val Loss: 1.0884 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  3.64it/s]\n",
            "Epoch 19/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 19 | Train Loss: 1.0562 | Val Loss: 1.0772 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.12it/s]\n",
            "Epoch 20/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 20 | Train Loss: 1.0524 | Val Loss: 1.0703 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 21, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.933854341506958\n",
            "    Max:  -1.6097354888916016\n",
            "    Mean: -3.000680446624756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 21 | Train Loss: 1.0485 | Val Loss: 1.0618 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.46it/s]\n",
            "Epoch 22/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 22 | Train Loss: 1.0460 | Val Loss: 1.0550 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.30it/s]\n",
            "Epoch 23/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 23 | Train Loss: 1.0444 | Val Loss: 1.0522 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.21it/s]\n",
            "Epoch 24/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 24 | Train Loss: 1.0399 | Val Loss: 1.0511 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.04it/s]\n",
            "Epoch 25/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 25 | Train Loss: 1.0387 | Val Loss: 1.0444 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 26, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -4.2526068687438965\n",
            "    Max:  -2.535902738571167\n",
            "    Mean: -3.3191471099853516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 26 | Train Loss: 1.0354 | Val Loss: 1.0401 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.39it/s]\n",
            "Epoch 27/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 27 | Train Loss: 1.0353 | Val Loss: 1.0385 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.07it/s]\n",
            "Epoch 28/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 28 | Train Loss: 1.0320 | Val Loss: 1.0375 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.37it/s]\n",
            "Epoch 29/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 29 | Train Loss: 1.0307 | Val Loss: 1.0350 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.28it/s]\n",
            "Epoch 30/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 30 | Train Loss: 1.0302 | Val Loss: 1.0333 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 31, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -4.657355785369873\n",
            "    Max:  -2.731320381164551\n",
            "    Mean: -3.5957584381103516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  3.88it/s]\n",
            "Epoch 31/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 31 | Train Loss: 1.0274 | Val Loss: 1.0319 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.39it/s]\n",
            "Epoch 32/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 32 | Train Loss: 1.0266 | Val Loss: 1.0304 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.14it/s]\n",
            "Epoch 33/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 33 | Train Loss: 1.0259 | Val Loss: 1.0286 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.39it/s]\n",
            "Epoch 34/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 34 | Train Loss: 1.0245 | Val Loss: 1.0273 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.47it/s]\n",
            "Epoch 35/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 35 | Train Loss: 1.0233 | Val Loss: 1.0260 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 36, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -4.613113880157471\n",
            "    Max:  -2.7895052433013916\n",
            "    Mean: -3.788024663925171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 36 | Train Loss: 1.0221 | Val Loss: 1.0239 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.29it/s]\n",
            "Epoch 37/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 37 | Train Loss: 1.0213 | Val Loss: 1.0225 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.28it/s]\n",
            "Epoch 38/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 38 | Train Loss: 1.0198 | Val Loss: 1.0208 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.85it/s]\n",
            "Epoch 39/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 39 | Train Loss: 1.0195 | Val Loss: 1.0202 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.12it/s]\n",
            "Epoch 40/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 40 | Train Loss: 1.0185 | Val Loss: 1.0198 | IoU: 1.0000\n",
            "\n",
            "🔁 Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 1, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -1.667335033416748\n",
            "    Max:  0.7744898200035095\n",
            "    Mean: -0.10266555845737457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 1 | Train Loss: 1.6304 | Val Loss: 1.6856 | IoU: 1.0000\n",
            "✅ Best model saved to saved_models/best_model_fold_2.pth (IoU=1.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.24it/s]\n",
            "Epoch 2/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 2 | Train Loss: 1.4189 | Val Loss: 1.5547 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.18it/s]\n",
            "Epoch 3/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 3 | Train Loss: 1.3193 | Val Loss: 1.3735 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.38it/s]\n",
            "Epoch 4/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 4 | Train Loss: 1.2623 | Val Loss: 1.2550 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.16it/s]\n",
            "Epoch 5/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 5 | Train Loss: 1.2224 | Val Loss: 1.1896 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 6, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.0704104900360107\n",
            "    Max:  -0.8188629150390625\n",
            "    Mean: -1.503871202468872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.41it/s]\n",
            "Epoch 6/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 6 | Train Loss: 1.1932 | Val Loss: 1.1553 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  3.86it/s]\n",
            "Epoch 7/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 7 | Train Loss: 1.1688 | Val Loss: 1.1332 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.13it/s]\n",
            "Epoch 8/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 8 | Train Loss: 1.1486 | Val Loss: 1.1209 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.19it/s]\n",
            "Epoch 9/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 9 | Train Loss: 1.1318 | Val Loss: 1.1141 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.37it/s]\n",
            "Epoch 10/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 10 | Train Loss: 1.1177 | Val Loss: 1.1057 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 11, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.596468448638916\n",
            "    Max:  -1.5297012329101562\n",
            "    Mean: -2.1608099937438965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 11 | Train Loss: 1.1058 | Val Loss: 1.1006 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.05it/s]\n",
            "Epoch 12/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 12 | Train Loss: 1.0955 | Val Loss: 1.1001 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.23it/s]\n",
            "Epoch 13/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 13 | Train Loss: 1.0867 | Val Loss: 1.1021 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.21it/s]\n",
            "Epoch 14/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 14 | Train Loss: 1.0790 | Val Loss: 1.1133 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  5.37it/s]\n",
            "Epoch 15/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 15 | Train Loss: 1.0723 | Val Loss: 1.1377 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 16, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.027567148208618\n",
            "    Max:  -2.0804381370544434\n",
            "    Mean: -2.653106212615967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 16 | Train Loss: 1.0664 | Val Loss: 1.1536 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.15it/s]\n",
            "Epoch 17/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 17 | Train Loss: 1.0613 | Val Loss: 1.1521 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.21it/s]\n",
            "Epoch 18/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 18 | Train Loss: 1.0568 | Val Loss: 1.1374 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.40it/s]\n",
            "Epoch 19/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 19 | Train Loss: 1.0527 | Val Loss: 1.1090 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.18it/s]\n",
            "Epoch 20/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 20 | Train Loss: 1.0491 | Val Loss: 1.0881 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 21, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.4123892784118652\n",
            "    Max:  -2.438033103942871\n",
            "    Mean: -3.0384531021118164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.90it/s]\n",
            "Epoch 21/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 21 | Train Loss: 1.0459 | Val Loss: 1.0742 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.14it/s]\n",
            "Epoch 22/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 22 | Train Loss: 1.0430 | Val Loss: 1.0635 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  4.24it/s]\n",
            "Epoch 23/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 23 | Train Loss: 1.0404 | Val Loss: 1.0555 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.06it/s]\n",
            "Epoch 24/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 24 | Train Loss: 1.0380 | Val Loss: 1.0494 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.18it/s]\n",
            "Epoch 25/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 25 | Train Loss: 1.0358 | Val Loss: 1.0449 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Epoch 26, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.705808639526367\n",
            "    Max:  -2.699151039123535\n",
            "    Mean: -3.3544163703918457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 26 | Train Loss: 1.0338 | Val Loss: 1.0411 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.12it/s]\n",
            "Epoch 27/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 27 | Train Loss: 1.0320 | Val Loss: 1.0378 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/40 [Train]: 100%|██████████| 3/3 [00:00<00:00,  6.26it/s]\n",
            "Epoch 28/40 [Val]: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 28 | Train Loss: 1.0303 | Val Loss: 1.0352 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/40 [Train]:  33%|███▎      | 1/3 [00:00<00:00,  3.10it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset YAML File\n",
        "\n",
        "A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. 😀"
      ],
      "metadata": {
        "id": "xE6ntKojSfSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```yaml\n",
        "# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\n",
        "\n",
        "# Crack-seg dataset by Ultralytics\n",
        "# Documentation: https://docs.ultralytics.com/datasets/segment/crack-seg/\n",
        "# Example usage: yolo train data=crack-seg.yaml\n",
        "# parent\n",
        "# ├── ultralytics\n",
        "# └── datasets\n",
        "#     └── crack-seg  ← downloads here (91.2 MB)\n",
        "\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: ../datasets/crack-seg # dataset root dir\n",
        "train: train/images # train images (relative to 'path') 3717 images\n",
        "val: valid/images # val images (relative to 'path') 112 images\n",
        "test: test/images # test images (relative to 'path') 200 images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: crack\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/crack-seg.zip\n",
        "```"
      ],
      "metadata": {
        "id": "h8go3HNgN0WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ],
      "metadata": {
        "id": "fMV-sNfiSt_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-seg.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=\"crack-seg.yaml\", epochs=3, imgsz=640, batch=64, workers=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgMYUvlNLvy",
        "outputId": "fd8387d4-b9c9-406c-a7f7-61a28c60d241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.90M/5.90M [00:00<00:00, 99.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=crack-seg.yaml, epochs=3, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=64, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "\n",
            "Dataset 'crack-seg.yaml' images not found ⚠️, missing path '/content/datasets/crack-seg/valid/images'\n",
            "Downloading https://ultralytics.com/assets/crack-seg.zip to '/content/datasets/crack-seg.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 91.1M/91.1M [00:02<00:00, 40.2MB/s]\n",
            "Unzipping /content/datasets/crack-seg.zip to /content/datasets/crack-seg...: 100%|██████████| 8061/8061 [00:01<00:00, 4783.99file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ✅ (5.0s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 41.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    683635  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
            "YOLO11n-seg summary: 355 layers, 2,842,803 parameters, 2,842,787 gradients, 10.4 GFLOPs\n",
            "\n",
            "Transferred 510/561 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/crack-seg/train/labels... 3717 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3717/3717 [00:03<00:00, 1105.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/crack-seg/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/crack-seg/valid/labels... 200 images, 1 backgrounds, 0 corrupt: 100%|██████████| 200/200 [00:00<00:00, 706.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/crack-seg/valid/labels.cache\n",
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      11.3G      1.349        2.3      2.286      1.316         15        640: 100%|██████████| 59/59 [01:34<00:00,  1.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.405      0.437      0.361      0.129      0.293      0.317      0.208     0.0421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3      11.3G      1.221      1.656      1.575      1.213          5        640: 100%|██████████| 59/59 [01:28<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.484       0.47      0.372      0.162      0.426      0.402      0.247     0.0643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3      11.5G      1.155      1.627      1.323      1.185         11        640: 100%|██████████| 59/59 [01:27<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<00:00,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.386      0.481      0.369      0.141      0.267      0.333      0.156     0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.083 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,834,763 parameters, 0 gradients, 10.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.485      0.476      0.371      0.161       0.42      0.398      0.243     0.0637\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataset sample image](https://github.com/ultralytics/docs/releases/download/0/crack-segmentation-sample.avif)"
      ],
      "metadata": {
        "id": "_Hapx6WkS--T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ],
      "metadata": {
        "id": "mKAUvDAbTEjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/path/to/best.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Inference using the model (img/video/stream)\n",
        "results = model.predict(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/crack-on-wall.jpg\", save=True)"
      ],
      "metadata": {
        "id": "nzTbeqK_TB6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b447bde9-2847-4863-d658-181c78d35258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://github.com/ultralytics/assets/releases/download/v0.0.0/crack-on-wall.jpg locally at crack-on-wall.jpg\n",
            "image 1/1 /content/crack-on-wall.jpg: 384x640 1 crack, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/9044c148-c157-47d6-87b4-5608593f5b70\" width=\"600\">"
      ],
      "metadata": {
        "id": "lmNKY3rWWsvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- 💡 ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- 💡 ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ✅        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ✅        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ✅        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ✅        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ✅        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ✅        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ✅        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ❌        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ✅        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ✅        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ✅        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ✅        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | ✅        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ✅        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | ✅        | `imgsz`, `int8`                                                      |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | ✅        | `imgsz`, `batch`, `name`                                             |"
      ],
      "metadata": {
        "id": "vWBYYdXhTkN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/path/to/best.pt\")  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "model.export(format=\"torchscript\")"
      ],
      "metadata": {
        "id": "S4nWG40CTlOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "c3db12b5-4f21-4c79-eea1-484057f2c7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,834,763 parameters, 0 gradients, 10.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 37, 8400), (1, 32, 160, 160)) (5.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1+cu124...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 4.8s, saved as '/content/best.torchscript' (11.4 MB)\n",
            "\n",
            "Export complete (5.7s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=segment model=/content/best.torchscript imgsz=640  \n",
            "Validate:        yolo val task=segment model=/content/best.torchscript imgsz=640 data=/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/crack-seg.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/best.torchscript'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}