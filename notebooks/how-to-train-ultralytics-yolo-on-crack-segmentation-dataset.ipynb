{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-train-ultralytics-yolo-on-crack-segmentation-dataset.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "\n",
        "\n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Crack segmentation with Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crack Segmentation using Ultralytics YOLO11\n",
        "\n",
        "This notebook acts as a starting point for training the YOLO11 model using the [crack segmentation dataset](https://docs.ultralytics.com/datasets/segment/crack-seg/)."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Structure\n",
        "\n",
        "The division of data within the Crack Segmentation Dataset is outlined as follows:\n",
        "\n",
        "- **Training set**: Consists of 3717 images with corresponding annotations.\n",
        "\n",
        "- **Testing set**: Comprises 112 images along with their respective annotations.\n",
        "\n",
        "- **Validation set**: Includes 200 images with their corresponding annotations."
      ],
      "metadata": {
        "id": "xypoYW_oYZAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "\n",
        "Crack segmentation finds practical applications in infrastructure maintenance, aiding in the identification and assessment of structural damage. It also plays a crucial role in enhancing road safety by enabling automated systems to detect and address pavement cracks for timely repairs.\n"
      ],
      "metadata": {
        "id": "R4SICbq5Yalg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Í∏∞Î≥∏ÏÑ§Ïπò Î∞è Í≤ΩÎ°úÏÑ§Ï†ï import Ï∂îÍ∞Ä\n",
        "# 1. Í∏∞Î≥∏ÏÑ§Ïπò Î∞è Í≤ΩÎ°úÏÑ§Ï†ï import Ï∂îÍ∞Ä\n",
        "!pip install -q scipy scikit-learn tensorboard\n",
        "\n",
        "# 2. ÌïÑÏöî Î™®Îìà ÏûÑÌè¨Ìä∏\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# 3. ÏïïÏ∂ï ÌååÏùº ÏóÖÎ°úÎìú\n",
        "print(\"‚ñ∂Ô∏è ÏïïÏ∂ï ÌååÏùºÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî (.zip)\")\n",
        "uploaded = files.upload()\n",
        "zip_filename = next(iter(uploaded))\n",
        "print(f\"‚úÖ ÏóÖÎ°úÎìú ÏôÑÎ£å: {zip_filename}\")\n",
        "\n",
        "# 4. ÏïïÏ∂ï Ìï¥Ï†ú\n",
        "extract_root = '.'\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_root)\n",
        "print(f\"‚úÖ ÏïïÏ∂ï Ìï¥Ï†ú ÏôÑÎ£å: '{extract_root}'Ïóê ÎÇ¥Ïö©Ïù¥ ÌíÄÎ†∏ÏäµÎãàÎã§\")\n",
        "\n",
        "# 5. CrackForest-dataset Ìè¥ÎçîÎ™Ö Ï†ïÎ¶¨\n",
        "target_dir = \"CrackForest-dataset\"\n",
        "src_dir = None\n",
        "\n",
        "for item in os.listdir(extract_root):\n",
        "    if item.startswith(\"CrackForest\") and os.path.isdir(item) and item != target_dir:\n",
        "        src_dir = item\n",
        "        break\n",
        "\n",
        "if src_dir:\n",
        "    if os.path.exists(target_dir):\n",
        "        print(f\"Í∏∞Ï°¥ '{target_dir}' Ìè¥ÎçîÍ∞Ä Ïù¥ÎØ∏ Ï°¥Ïû¨Ìï©ÎãàÎã§. ÏÇ≠Ï†ú ÌõÑ Ïù¥Î¶Ñ Î≥ÄÍ≤ΩÏùÑ ÏßÑÌñâÌï©ÎãàÎã§.\")\n",
        "        shutil.rmtree(target_dir)\n",
        "    os.rename(src_dir, target_dir)\n",
        "    print(f\"üìÅ Ìè¥Îçî Ïù¥Î¶ÑÏùÑ '{src_dir}' ‚ûú '{target_dir}' ÏúºÎ°ú Î≥ÄÍ≤ΩÌñàÏäµÎãàÎã§.\")\n",
        "else:\n",
        "    print(f\"Î≥ÄÍ≤ΩÌï† Ìè¥ÎçîÍ∞Ä ÏóÜÍ±∞ÎÇò Ïù¥ÎØ∏ '{target_dir}' Ìè¥ÎçîÍ∞Ä Ï°¥Ïû¨Ìï©ÎãàÎã§.\")\n",
        "\n",
        "# 6. Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°ú ÏÑ§Ï†ï Î∞è Í≤ÄÏ¶ù\n",
        "dataset_dir = os.path.join(extract_root, target_dir)\n",
        "if not os.path.exists(dataset_dir):\n",
        "    raise FileNotFoundError(f\"‚ùå '{target_dir}' Ìè¥ÎçîÍ∞Ä Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§. ÏïïÏ∂ï Íµ¨Ï°∞Î•º ÌôïÏù∏Ìï¥ Ï£ºÏÑ∏Ïöî.\")\n",
        "\n",
        "img_dir = os.path.join(dataset_dir, 'image')\n",
        "gt_dir = os.path.join(dataset_dir, 'groundTruth')\n",
        "seg_dir = os.path.join(dataset_dir, 'seg')\n",
        "\n",
        "for subdir, name in zip([img_dir, gt_dir, seg_dir], ['image', 'groundTruth', 'seg']):\n",
        "    if not os.path.exists(subdir):\n",
        "        raise FileNotFoundError(f\"‚ùå '{name}/' Ìè¥ÎçîÍ∞Ä '{dataset_dir}' ÎÇ¥Ïóê ÏóÜÏäµÎãàÎã§. ÏïïÏ∂ï Íµ¨Ï°∞Î•º ÌôïÏù∏Ìï¥ Ï£ºÏÑ∏Ïöî.\")\n",
        "\n",
        "# 7. Ï∂úÎ†• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
        "os.makedirs('runs', exist_ok=True)\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# 8. Í≤ΩÎ°ú Ï∂úÎ†•\n",
        "print(f\"‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î£®Ìä∏: {dataset_dir}\")\n",
        "print(f\"üìÅ Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî: {img_dir}\")\n",
        "print(f\"üìÅ ÎßàÏä§ÌÅ¨ Ìè¥Îçî: {gt_dir}\")\n",
        "print(f\"üìÅ Segmentation Ìè¥Îçî: {seg_dir}\")\n",
        "\n",
        "# 9. Ïù¥ÎØ∏ÏßÄ Î∞è .mat ÌååÏùº Í≤ΩÎ°ú ÏàòÏßë (ÌôïÏû•Ïûê ÏûêÎèô Í∞êÏßÄ)\n",
        "supported_img_exts = ['png', 'jpg', 'jpeg', 'bmp', 'tif', 'tiff']\n",
        "img_paths = []\n",
        "for ext in supported_img_exts:\n",
        "    img_paths.extend(glob.glob(os.path.join(img_dir, f\"*.{ext}\")))\n",
        "img_paths = sorted(img_paths)\n",
        "mat_paths = sorted(glob.glob(os.path.join(gt_dir, \"*.mat\")))\n",
        "\n",
        "# üîç ÎîîÎ≤ÑÍπÖ Î°úÍ∑∏\n",
        "print(f\"\\n‚úÖ Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú: {img_dir}\")\n",
        "print(f\"üñºÔ∏è Í∞êÏßÄÎêú Ïù¥ÎØ∏ÏßÄ Ïàò: {len(img_paths)}\")\n",
        "if len(img_paths) > 0:\n",
        "    print(\"‚úÖ Ïù¥ÎØ∏ÏßÄ ÏÉòÌîå:\", img_paths[:3])\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è ÏßÄÏõêÎêòÎäî Ïù¥ÎØ∏ÏßÄ ÌôïÏû•ÏûêÎ°ú Îêú ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§. Ïã§Ï†ú ÌôïÏû•Ïûê ÌôïÏù∏ ÌïÑÏöî\")\n",
        "print(f\"üìê Í∞êÏßÄÎêú GroundTruth Ïàò: {len(mat_paths)}\")\n",
        "\n",
        "# 10. Ïù¥ÎØ∏ÏßÄÏôÄ ÎßàÏä§ÌÅ¨ Ïù¥Î¶Ñ Í∏∞Ï§ÄÏúºÎ°ú Í≥µÌÜµ Îß§Ïπ≠\n",
        "img_names = set([os.path.splitext(os.path.basename(p))[0] for p in img_paths])\n",
        "mat_names = set([os.path.splitext(os.path.basename(p))[0] for p in mat_paths])\n",
        "\n",
        "common_keys = sorted(img_names & mat_names)\n",
        "img_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in img_paths}\n",
        "mat_dict = {os.path.splitext(os.path.basename(p))[0]: p for p in mat_paths}\n",
        "\n",
        "img_paths_matched = [img_dict[k] for k in common_keys]\n",
        "mat_paths_matched = [mat_dict[k] for k in common_keys]\n",
        "\n",
        "# ÏÉòÌîå ÎùºÎ≤® (Ïòà: Î™®Îëê 0ÏúºÎ°ú ÏÑ§Ï†ï)\n",
        "labels = [0] * len(common_keys)\n",
        "\n",
        "print(f\"\\n‚úÖ Îß§Ïπ≠Îêú Ïù¥ÎØ∏ÏßÄ Ïàò: {len(img_paths_matched)}\")\n",
        "print(f\"‚úÖ Îß§Ïπ≠Îêú ÎßàÏä§ÌÅ¨ Ïàò: {len(mat_paths_matched)}\")\n",
        "print(f\"üß∑ Í≥µÌÜµÎêú ÌååÏùº prefix ÏòàÏãú: {common_keys[:3]}\")\n",
        "\n",
        "# 11. Train/Validation Î∂ÑÎ¶¨ (ÌïÑÏöî Ïãú)\n",
        "if len(img_paths_matched) == 0:\n",
        "    raise ValueError(\"‚ùå Ïù¥ÎØ∏ÏßÄÏôÄ GroundTruthÍ∞Ä Îß§Ïπ≠ÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. ÌååÏùº Ïù¥Î¶ÑÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")\n",
        "\n",
        "tr = list(range(0, int(0.8 * len(img_paths_matched))))\n",
        "va = list(range(int(0.8 * len(img_paths_matched)), len(img_paths_matched)))\n",
        "\n",
        "print(f\"\\nüß™ Train indices: {min(tr)} ~ {max(tr)}\")\n",
        "print(f\"üß™ Validation indices: {min(va)} ~ {max(va)}\")\n",
        "\n",
        "# 12. ÎÇ¥Î∂Ä Ìè¥Îçî Íµ¨Ï°∞ Ï∂úÎ†•\n",
        "print(\"\\nüìÇ 'CrackForest-dataset' Ìè¥Îçî ÎÇ¥Î∂Ä Íµ¨Ï°∞:\")\n",
        "for root, dirs, files in os.walk(dataset_dir):\n",
        "    level = root.replace(dataset_dir, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{subindent}{f}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... Ïô∏ {len(files)-5}Í∞ú Îçî\")\n"
      ],
      "metadata": {
        "id": "RMD0OqCyqjlw",
        "outputId": "a2fae57c-bf1c-45ca-d5f3-6225722d0659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ñ∂Ô∏è ÏïïÏ∂ï ÌååÏùºÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî (.zip)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6a6a23b1-54e8-4ec9-8d9d-5f9e7ab12fc6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6a6a23b1-54e8-4ec9-8d9d-5f9e7ab12fc6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving CrackForest-dataset-master.zip to CrackForest-dataset-master.zip\n",
            "‚úÖ ÏóÖÎ°úÎìú ÏôÑÎ£å: CrackForest-dataset-master.zip\n",
            "‚úÖ ÏïïÏ∂ï Ìï¥Ï†ú ÏôÑÎ£å: '.'Ïóê ÎÇ¥Ïö©Ïù¥ ÌíÄÎ†∏ÏäµÎãàÎã§\n",
            "üìÅ Ìè¥Îçî Ïù¥Î¶ÑÏùÑ 'CrackForest-dataset-master' ‚ûú 'CrackForest-dataset' ÏúºÎ°ú Î≥ÄÍ≤ΩÌñàÏäµÎãàÎã§.\n",
            "‚úÖ Îç∞Ïù¥ÌÑ∞ÏÖã Î£®Ìä∏: ./CrackForest-dataset\n",
            "üìÅ Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî: ./CrackForest-dataset/image\n",
            "üìÅ ÎßàÏä§ÌÅ¨ Ìè¥Îçî: ./CrackForest-dataset/groundTruth\n",
            "üìÅ Segmentation Ìè¥Îçî: ./CrackForest-dataset/seg\n",
            "\n",
            "‚úÖ Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú: ./CrackForest-dataset/image\n",
            "üñºÔ∏è Í∞êÏßÄÎêú Ïù¥ÎØ∏ÏßÄ Ïàò: 155\n",
            "‚úÖ Ïù¥ÎØ∏ÏßÄ ÏÉòÌîå: ['./CrackForest-dataset/image/001.jpg', './CrackForest-dataset/image/002.jpg', './CrackForest-dataset/image/003.jpg']\n",
            "üìê Í∞êÏßÄÎêú GroundTruth Ïàò: 118\n",
            "\n",
            "‚úÖ Îß§Ïπ≠Îêú Ïù¥ÎØ∏ÏßÄ Ïàò: 118\n",
            "‚úÖ Îß§Ïπ≠Îêú ÎßàÏä§ÌÅ¨ Ïàò: 118\n",
            "üß∑ Í≥µÌÜµÎêú ÌååÏùº prefix ÏòàÏãú: ['001', '002', '003']\n",
            "\n",
            "üß™ Train indices: 0 ~ 93\n",
            "üß™ Validation indices: 94 ~ 117\n",
            "\n",
            "üìÇ 'CrackForest-dataset' Ìè¥Îçî ÎÇ¥Î∂Ä Íµ¨Ï°∞:\n",
            "CrackForest-dataset/\n",
            "  README.md\n",
            "  seg/\n",
            "    047.seg\n",
            "    010.seg\n",
            "    114.seg\n",
            "    086.seg\n",
            "    103.seg\n",
            "    ... Ïô∏ 113Í∞ú Îçî\n",
            "  groundTruth/\n",
            "    090.mat\n",
            "    023.mat\n",
            "    075.mat\n",
            "    012.mat\n",
            "    071.mat\n",
            "    ... Ïô∏ 113Í∞ú Îçî\n",
            "  image/\n",
            "    324.jpg\n",
            "    046.jpg\n",
            "    204.jpg\n",
            "    091.jpg\n",
            "    018.jpg\n",
            "    ... Ïô∏ 151Í∞ú Îçî\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1-1 ÏïÑÎûòÎ•º Ïã§ÌñâÌï¥Ïïº ÌõàÎ†®ÏÖÄÏù¥ Ïã§Îê®\n",
        "#Îç∞Ïù¥ÌÑ∞ÏÖã Í≤ΩÎ°úÏÑ§Ï†ï\n",
        "\n",
        "!pip install -q scipy scikit-learn tensorboard\n",
        "\n",
        "import os, random, zipfile, urllib.request\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "root = '/content/CrackForest-dataset'\n",
        "img_dir = os.path.join(root, 'image')\n",
        "gt_dir = os.path.join(root, 'groundTruth')\n",
        "os.makedirs('runs', exist_ok=True)\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥Î°úÎìú\n",
        "if not os.path.exists(root):\n",
        "    url = 'https://www.dropbox.com/s/06e4r7dk6n31xgk/CrackForest-dataset.zip?dl=1'\n",
        "    zip_path = '/content/CrackForest.zip'\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "M94XFCGirOfQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 ÏãúÎìú Î∞è ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "seed_everything()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ÏÇ¨Ïö© Ï§ëÏù∏ ÎîîÎ∞îÏù¥Ïä§: {device}\")\n"
      ],
      "metadata": {
        "id": "BjUp43YrrW24",
        "outputId": "a5c32871-fb3d-4955-cab2-45405e25b2c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÏÇ¨Ïö© Ï§ëÏù∏ ÎîîÎ∞îÏù¥Ïä§: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3 ÌååÏùº Î¶¨Ïä§Ìä∏ ÌïÑÌÑ∞ÎßÅ\n",
        "def get_file_num(filename):\n",
        "    return os.path.splitext(filename)[0]\n",
        "\n",
        "all_imgs = sorted(os.listdir(img_dir))\n",
        "all_mats = sorted(os.listdir(gt_dir))\n",
        "mat_nums = set(get_file_num(f) for f in all_mats)\n",
        "\n",
        "filtered_imgs = [f for f in all_imgs if get_file_num(f) in mat_nums]\n",
        "filtered_mats = [f for f in all_mats if get_file_num(f) in [get_file_num(i) for i in filtered_imgs]]\n",
        "\n",
        "img_paths = [os.path.join(img_dir, f) for f in filtered_imgs]\n",
        "mat_paths = [os.path.join(gt_dir, f) for f in filtered_mats]\n",
        "labels = [1] * len(img_paths)\n",
        "\n",
        "print(f\"Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ Ïàò: {len(all_imgs)}\")\n",
        "print(f\"groundTruth .mat ÌååÏùº Ïàò: {len(all_mats)}\")\n",
        "print(f\"ÌïÑÌÑ∞ÎßÅÎêú Ïù¥ÎØ∏ÏßÄ Ïàò: {len(img_paths)}\")\n"
      ],
      "metadata": {
        "id": "9G0fDQxore6m",
        "outputId": "4469e13a-221a-4663-a6f2-b84ff2a69501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ Ïàò: 156\n",
            "groundTruth .mat ÌååÏùº Ïàò: 118\n",
            "ÌïÑÌÑ∞ÎßÅÎêú Ïù¥ÎØ∏ÏßÄ Ïàò: 118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 CrackDataset ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from torchvision import transforms\n",
        "\n",
        "class CrackDataset(Dataset):\n",
        "    def __init__(self, image_paths, mat_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mat_paths = mat_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "\n",
        "        try:\n",
        "            mat = scipy.io.loadmat(self.mat_paths[idx])\n",
        "            gt = mat.get(\"groundTruth\")\n",
        "\n",
        "            if gt is None:\n",
        "                raise ValueError(\"groundTruth ÌÇ§Í∞Ä ÏóÜÏùå\")\n",
        "\n",
        "            # (1,1) Íµ¨Ï°∞Ï≤¥ Î∞∞Ïó¥ÏóêÏÑú Boundaries Ï∂îÏ∂ú\n",
        "            boundaries_obj_array = gt[0, 0]['Boundaries']  # (1,) object array\n",
        "            mask_array = np.array(boundaries_obj_array[0])  # Ïã§Ï†ú (H,W) numpy Î∞∞Ïó¥\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Mask Ï∂îÏ∂ú Ïò§Î•ò - {self.mat_paths[idx]}: {e}\")\n",
        "\n",
        "        # ÎßàÏä§ÌÅ¨ ÌõÑÏ≤òÎ¶¨\n",
        "        mask = Image.fromarray((mask_array > 0.5).astype(np.uint8) * 255)\n",
        "\n",
        "        # Ïù¥ÎØ∏ÏßÄ Î∞è ÎßàÏä§ÌÅ¨ Î¶¨ÏÇ¨Ïù¥Ï¶à\n",
        "        image = image.resize((64, 64))\n",
        "        mask = mask.resize((64, 64))\n",
        "\n",
        "        # Tensor Î≥ÄÌôò\n",
        "        image = self.transform(image) if self.transform else transforms.ToTensor()(image)\n",
        "        mask = transforms.ToTensor()(mask)  # ‚Üí [0,1] Î≤îÏúÑ float tensor\n",
        "\n",
        "        #return image, (mask > 0.5).float()\n",
        "        return image, mask  # threshold Ï†ÅÏö© X\n"
      ],
      "metadata": {
        "id": "SsE7Cqbcrh0V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Î™®Îç∏Ï†ïÏùò UNet + CBAM (Channel & Spatial Attention)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=8):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        return self.sigmoid(avg_out + max_out) * x\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
        "        return self.sigmoid(self.conv(x_cat)) * x\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_planes):\n",
        "        super().__init__()\n",
        "        self.channel_attention = ChannelAttention(in_planes)\n",
        "        self.spatial_attention = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.channel_attention(x)\n",
        "        x = self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "#Í≤©ÏûêÎ¨¥Îä¨ Ìï¥Í≤∞Ï§ë\n",
        "class UNetWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        def conv_block(in_ch, out_ch):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_ch),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        # Ïù∏ÏΩîÎçî\n",
        "        self.enc1 = nn.Sequential(conv_block(3, 64), CBAM(64))\n",
        "        self.enc2 = nn.Sequential(conv_block(64, 128), CBAM(128))\n",
        "        self.enc3 = nn.Sequential(conv_block(128, 256), CBAM(256))\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.mid = conv_block(256, 512)\n",
        "\n",
        "        # ÏóÖÏÉòÌîåÎßÅ: ConvTranspose ‚Üí Upsample + Conv2d\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "            nn.Conv2d(512, 256, kernel_size=1)\n",
        "        )\n",
        "        self.dec2 = conv_block(512, 256)\n",
        "\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "            nn.Conv2d(256, 128, kernel_size=1)\n",
        "        )\n",
        "        self.dec1 = conv_block(256, 128)\n",
        "\n",
        "        # Ï∂úÎ†• Î†àÏù¥Ïñ¥\n",
        "        self.final = nn.Conv2d(128, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)                   # (B, 64, 64, 64)\n",
        "        e2 = self.enc2(self.pool(e1))      # (B, 128, 32, 32)\n",
        "        e3 = self.enc3(self.pool(e2))      # (B, 256, 16, 16)\n",
        "        m = self.mid(self.pool(e3))        # (B, 512, 8, 8)\n",
        "\n",
        "        d2 = self.up2(m)                   # (B, 256, 16, 16)\n",
        "        d2 = self.dec2(torch.cat([d2, e3], dim=1))  # (B, 256, 16, 16)\n",
        "\n",
        "        d1 = self.up1(d2)                  # (B, 128, 32, 32)\n",
        "        d1 = self.dec1(torch.cat([d1, e2], dim=1))  # (B, 128, 32, 32)\n",
        "\n",
        "        #out = torch.sigmoid(self.final(d1))  # (B, 1, 32, 32)\n",
        "        #BCEDiceLossÏôÄ Î™®Îç∏ Ï∂îÎ°† ÏãúÏ†êÏóê Îã§Ïãú sigmoidÎ•º Ï§ëÎ≥µÌò∏Ï∂ú Ï†úÍ±∞\n",
        "        out = self.final(d1)\n",
        "\n",
        "        # ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú ÏûÖÎ†• ÌÅ¨Í∏∞(64x64)Ïóê ÎßûÏ∂∞Î≥¥Ï†ï\n",
        "        #Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú resizeÎ•º Î®ºÏ†Ä ÌñàÍ∏∞ ÎïåÎ¨∏Ïóê Î™®Îç∏ Ï∂úÎ†•Í≥º Ground TruthÎäî Ïù¥ÎØ∏ Í∞ôÏùÄ ÌÅ¨Í∏∞ Í∑∏ÎÉ•Îë¨ÎèÑ Î¨¥Î∞©\n",
        "        #Ïù¥ Í≤ΩÏö∞ F.interpolate(..., size=(64,64))Îäî Ï§ëÎ≥µÏùº Ïàò ÏûàÏäµÎãàÎã§\n",
        "        return F.interpolate(out, size=(64, 64), mode='bilinear', align_corners=False)"
      ],
      "metadata": {
        "id": "0l3aAwpMrulW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6 ÏÜêÏã§Ìï®Ïàò Î∞è Î©îÌä∏Î¶≠\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def forward(self, inputs, targets, smooth=1e-6):\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        intersection = (inputs * targets).sum()\n",
        "        return 1 - (2 * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bce = nn.BCELoss()\n",
        "        self.dice = DiceLoss()\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        inputs = torch.sigmoid(inputs)  #Î™®Îç∏ Ï∂úÎ†•ÏùÄ Î°úÏßì(logits)Ïù¥Í≥† ÌôïÎ•†Î°ú Î≥ÄÌôò\n",
        "        return self.bce(inputs, targets) + self.dice(inputs, targets)\n",
        "\n",
        "class IoUMetric:\n",
        "    def __call__(self, preds, masks):\n",
        "        preds = (preds > 0.5).float()\n",
        "        masks = masks.float()\n",
        "        intersection = (preds * masks).sum((1, 2, 3))\n",
        "        union = (preds + masks - preds * masks).sum((1, 2, 3))\n",
        "        iou = (intersection + 1e-6) / (union + 1e-6)\n",
        "        return iou.mean().item()\n"
      ],
      "metadata": {
        "id": "TA_HNa-0r8e1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Í∏∞Î≥∏ Transform ÏÑ§Ï†ïÏ†ï\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "TyjASzHAuCOW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8 K-Fold ÌïôÏäµ Î∞è ÌèâÍ∞Ä Î£®ÌîÑ Ìï®Ïàò Ï†ïÏùò\n",
        "#train_and_evaluate()\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def train_and_evaluate(img_paths, mat_paths, labels, num_epochs=20, batch_size=32, learning_rate=1e-3, k_folds=5):\n",
        "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "    criterion = BCEDiceLoss()\n",
        "    metric_fn = IoUMetric()\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(img_paths, labels)):\n",
        "        print(f\"\\nüîÅ Fold {fold + 1}/{k_folds}\")\n",
        "        writer = SummaryWriter(log_dir=f\"runs/fold_{fold+1}\")\n",
        "\n",
        "        train_dataset = CrackDataset([img_paths[i] for i in train_idx],\n",
        "                                     [mat_paths[i] for i in train_idx],\n",
        "                                     transform=transform)\n",
        "        val_dataset = CrackDataset([img_paths[i] for i in val_idx],\n",
        "                                   [mat_paths[i] for i in val_idx],\n",
        "                                   transform=transform)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "        model = UNetWithAttention().to(device)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        best_iou = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            for batch_idx, (images, masks) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")):\n",
        "            #for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                preds = model(images)\n",
        "                loss = criterion(preds, masks)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                # üîç Ïó¨Í∏∞ÏÑú ÏòàÏ∏° ÎßàÏä§ÌÅ¨ ÌÜµÍ≥Ñ ÌôïÏù∏ (Ï≤´ Î∞∞ÏπòÎßå)\n",
        "                #if batch_idx % 10 == 0:  #Ï†ïÌï¥ÏßÑ Í∞ÑÍ≤©ÎßàÎã§ Ï∂úÎ†•\n",
        "                #if batch_idx == 0:  #Îß§ ÏóêÌè≠ Ï≤´ Î∞∞ÏπòÎßå Ï∂úÎ†•\n",
        "                #if batch_idx == 0 and epoch == 0:\n",
        "                if batch_idx == 0 and epoch % 5 == 0:  #ÌïôÏäµÏßÑÌñâÏÉÅÌÉúÏóê Îî∞Î•∏ Î≥ÄÌôîÌôïÏù∏\n",
        "                    print(f\"\\nüîç Epoch {epoch+1}, Batch {batch_idx+1}\")\n",
        "                    print(\"  Predicted mask stats:\")\n",
        "                    print(\"    Min: \", preds.min().item())\n",
        "                    print(\"    Max: \", preds.max().item())\n",
        "                    print(\"    Mean:\", preds.mean().item())\n",
        "\n",
        "            train_loss /= len(train_loader)\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            iou_score = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
        "                    images, masks = images.to(device), masks.to(device)\n",
        "                    preds = model(images)\n",
        "                    loss = criterion(preds, masks)\n",
        "                    val_loss += loss.item()\n",
        "                    iou_score += metric_fn(preds, masks)\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            iou_score /= len(val_loader)\n",
        "\n",
        "            print(f\"[Fold {fold+1}] Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | IoU: {iou_score:.4f}\")\n",
        "            writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n",
        "            writer.add_scalar(\"IoU\", iou_score, epoch)\n",
        "\n",
        "            # Î™®Îç∏ Ï†ÄÏû•\n",
        "            if iou_score > best_iou:\n",
        "                best_iou = iou_score\n",
        "                model_path = f\"saved_models/best_model_fold_{fold+1}.pth\"\n",
        "                torch.save(model.state_dict(), model_path)\n",
        "                print(f\"‚úÖ Best model saved to {model_path} (IoU={best_iou:.4f})\")\n",
        "\n",
        "        writer.close()\n"
      ],
      "metadata": {
        "id": "cXTIjJXQuYvN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 9 Ï∂îÎ°† Î∞è ÏãúÍ∞ÅÌôî Ìï®Ïàò 2DÎ°ú Ï∂îÏ∂úÎ°ú ÏàòÏ†ï ÏΩîÎìú\n",
        "#segmentation Ï∂îÍ∞Ä\n",
        "#ÏûêÎèô vmin/max + contrast Ïä§ÏºÄÏùºÎßÅ Ìè¨Ìï®\n",
        "def predict_and_visualize(model_path, img_path, mat_path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import scipy.io\n",
        "    from torchvision import transforms\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Ï†ÑÏ≤òÎ¶¨\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    input_tensor = transform(img).unsqueeze(0)  # (1, 3, 64, 64)\n",
        "\n",
        "    # Î™®Îç∏ Î°úÎìú\n",
        "    model = UNetWithAttention()  # ÏÇ¨Ïö© Ï§ëÏù∏ Î™®Îç∏ ÌÅ¥ÎûòÏä§Î™ÖÏóê ÎßûÍ≤å ÏàòÏ†ï\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
        "    model.eval()\n",
        "\n",
        "    # ÏòàÏ∏° (logits ‚Üí ÌôïÎ•† ‚Üí numpy)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_mask = torch.sigmoid(output).squeeze().numpy()\n",
        "\n",
        "    # .mat ÌååÏùºÏóêÏÑú GT Ï∂îÏ∂ú\n",
        "    mat = scipy.io.loadmat(mat_path)\n",
        "    gt_struct = mat[\"groundTruth\"][0, 0]\n",
        "\n",
        "    # Boundaries\n",
        "    boundaries = gt_struct[\"Boundaries\"]\n",
        "    if isinstance(boundaries, np.ndarray) and boundaries.dtype == object:\n",
        "        boundary_mask = boundaries[0, 0]\n",
        "    else:\n",
        "        boundary_mask = boundaries\n",
        "    if isinstance(boundary_mask, np.ndarray) and boundary_mask.dtype == object:\n",
        "        boundary_mask = boundary_mask[0]\n",
        "\n",
        "    if not isinstance(boundary_mask, np.ndarray) or boundary_mask.ndim != 2:\n",
        "        raise ValueError(f\"Invalid boundary mask shape: {boundary_mask.shape if isinstance(boundary_mask, np.ndarray) else type(boundary_mask)}\")\n",
        "\n",
        "    # Segmentation\n",
        "    segmentation = gt_struct[\"Segmentation\"]\n",
        "    if isinstance(segmentation, np.ndarray) and segmentation.dtype == object:\n",
        "        seg_mask = segmentation[0, 0]\n",
        "    else:\n",
        "        seg_mask = segmentation\n",
        "    if isinstance(seg_mask, np.ndarray) and seg_mask.dtype == object:\n",
        "        seg_mask = seg_mask[0]\n",
        "\n",
        "    if not isinstance(seg_mask, np.ndarray) or seg_mask.ndim != 2:\n",
        "        raise ValueError(f\"Invalid segmentation mask shape: {seg_mask.shape if isinstance(seg_mask, np.ndarray) else type(seg_mask)}\")\n",
        "\n",
        "    # GT ÎßàÏä§ÌÅ¨ Î¶¨ÏÇ¨Ïù¥Ï¶à\n",
        "    boundary_resized = Image.fromarray((boundary_mask * 255).astype(np.uint8)).resize((64, 64))\n",
        "    seg_resized = Image.fromarray((seg_mask * 255).astype(np.uint8)).resize((64, 64))\n",
        "    boundary_resized = np.array(boundary_resized) / 255.0\n",
        "    seg_resized = np.array(seg_resized) / 255.0\n",
        "\n",
        "    # Binary threshold for prediction Thresholding (ÏÑ†ÌÉùÏ†Å Ï∂îÍ∞Ä)\n",
        "    pred_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    # ÏòàÏ∏° ÎßàÏä§ÌÅ¨ contrast Ï°∞Ï†ïÏö© Ïä§ÏºÄÏùºÎßÅ (ÏÑ†ÌÉùÏÇ¨Ìï≠)\n",
        "    contrast_scale = 20\n",
        "\n",
        "    # ÏãúÍ∞ÅÌôî\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(boundary_resized, cmap=\"gray\")\n",
        "    axes[1].set_title(\"Ground Truth (Boundary)\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    axes[2].imshow(seg_resized, cmap=\"gray\")\n",
        "    axes[2].set_title(\"Ground Truth (Segmentation)\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    #axes[3].imshow(pred_mask, cmap=\"gray\", vmin=0, vmax=1)\n",
        "    #axes[3].set_title(\"Predicted (Prob)\")\n",
        "    #axes[3].axis(\"off\")\n",
        "\n",
        "    axes[3].imshow(pred_mask * contrast_scale, cmap=\"gray\")\n",
        "    axes[3].set_title(\"Predicted (Prob x {})\".format(contrast_scale))\n",
        "    axes[3].axis(\"off\")\n",
        "\n",
        "    axes[4].imshow(pred_binary, cmap=\"gray\")\n",
        "    axes[4].set_title(\"Predicted (Binary > 0.5)\")\n",
        "    axes[4].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iZrDQVIyubll"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 ÏµúÏ¢ÖÎ≤ÑÏ†Ñ ÌïôÏäµ Ïã§Ìñâ epoch 40\n",
        "train_and_evaluate(img_paths_matched, mat_paths_matched, labels, num_epochs=40, batch_size=32, learning_rate=1e-3, k_folds=5)\n",
        "\n",
        "# Ï∂îÎ°† ÏòàÏãú (ÌïôÏäµ ÌõÑ ÏÇ¨Ïö©)\n",
        "predict_and_visualize(\"saved_models/best_model_fold_1.pth\", img_paths_matched[0], mat_paths_matched[0])\n"
      ],
      "metadata": {
        "id": "_TfLfRTPuepe",
        "outputId": "360415cf-06d2-44d1-80b0-65b239af4d16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÅ Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:03<00:06,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 1, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -1.0045570135116577\n",
            "    Max:  3.224926710128784\n",
            "    Mean: 0.03939331695437431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:03<00:00,  1.18s/it]\n",
            "Epoch 1/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 1 | Train Loss: 1.7313 | Val Loss: 1.7561 | IoU: 1.0000\n",
            "‚úÖ Best model saved to saved_models/best_model_fold_1.pth (IoU=1.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.49it/s]\n",
            "Epoch 2/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 2 | Train Loss: 1.5106 | Val Loss: 1.7761 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.72it/s]\n",
            "Epoch 3/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 3 | Train Loss: 1.3887 | Val Loss: 1.7070 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.06it/s]\n",
            "Epoch 4/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 4 | Train Loss: 1.2949 | Val Loss: 1.5989 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.96it/s]\n",
            "Epoch 5/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 5 | Train Loss: 1.2604 | Val Loss: 1.4574 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 6, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.180427074432373\n",
            "    Max:  -0.4370596408843994\n",
            "    Mean: -1.3873008489608765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 6 | Train Loss: 1.2244 | Val Loss: 1.3850 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.37it/s]\n",
            "Epoch 7/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 7 | Train Loss: 1.1968 | Val Loss: 1.3465 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.95it/s]\n",
            "Epoch 8/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 8 | Train Loss: 1.1708 | Val Loss: 1.3105 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.33it/s]\n",
            "Epoch 9/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 9 | Train Loss: 1.1608 | Val Loss: 1.2761 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.36it/s]\n",
            "Epoch 10/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 10 | Train Loss: 1.1397 | Val Loss: 1.2473 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 11, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.689789295196533\n",
            "    Max:  -0.5752020478248596\n",
            "    Mean: -1.982884168624878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 11 | Train Loss: 1.1238 | Val Loss: 1.2221 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.25it/s]\n",
            "Epoch 12/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 12 | Train Loss: 1.1087 | Val Loss: 1.2018 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.31it/s]\n",
            "Epoch 13/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 13 | Train Loss: 1.0974 | Val Loss: 1.1765 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.19it/s]\n",
            "Epoch 14/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 14 | Train Loss: 1.0847 | Val Loss: 1.1460 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.80it/s]\n",
            "Epoch 15/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 15 | Train Loss: 1.0783 | Val Loss: 1.1255 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Train]:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:00<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 16, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.558109760284424\n",
            "    Max:  -1.1151328086853027\n",
            "    Mean: -2.5579943656921387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.29it/s]\n",
            "Epoch 16/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 16 | Train Loss: 1.0731 | Val Loss: 1.1135 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.98it/s]\n",
            "Epoch 17/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 17 | Train Loss: 1.0639 | Val Loss: 1.1020 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.04it/s]\n",
            "Epoch 18/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 18 | Train Loss: 1.0611 | Val Loss: 1.0884 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.64it/s]\n",
            "Epoch 19/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 19 | Train Loss: 1.0562 | Val Loss: 1.0772 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.12it/s]\n",
            "Epoch 20/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 20 | Train Loss: 1.0524 | Val Loss: 1.0703 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 21, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.933854341506958\n",
            "    Max:  -1.6097354888916016\n",
            "    Mean: -3.000680446624756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 21 | Train Loss: 1.0485 | Val Loss: 1.0618 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.46it/s]\n",
            "Epoch 22/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 22 | Train Loss: 1.0460 | Val Loss: 1.0550 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.30it/s]\n",
            "Epoch 23/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 23 | Train Loss: 1.0444 | Val Loss: 1.0522 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.21it/s]\n",
            "Epoch 24/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 24 | Train Loss: 1.0399 | Val Loss: 1.0511 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.04it/s]\n",
            "Epoch 25/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 25 | Train Loss: 1.0387 | Val Loss: 1.0444 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 26, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -4.2526068687438965\n",
            "    Max:  -2.535902738571167\n",
            "    Mean: -3.3191471099853516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 26 | Train Loss: 1.0354 | Val Loss: 1.0401 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.39it/s]\n",
            "Epoch 27/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 27 | Train Loss: 1.0353 | Val Loss: 1.0385 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.07it/s]\n",
            "Epoch 28/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 28 | Train Loss: 1.0320 | Val Loss: 1.0375 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.37it/s]\n",
            "Epoch 29/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 29 | Train Loss: 1.0307 | Val Loss: 1.0350 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.28it/s]\n",
            "Epoch 30/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 30 | Train Loss: 1.0302 | Val Loss: 1.0333 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 31, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -4.657355785369873\n",
            "    Max:  -2.731320381164551\n",
            "    Mean: -3.5957584381103516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.88it/s]\n",
            "Epoch 31/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 31 | Train Loss: 1.0274 | Val Loss: 1.0319 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.39it/s]\n",
            "Epoch 32/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 32 | Train Loss: 1.0266 | Val Loss: 1.0304 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.14it/s]\n",
            "Epoch 33/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 33 | Train Loss: 1.0259 | Val Loss: 1.0286 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.39it/s]\n",
            "Epoch 34/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 34 | Train Loss: 1.0245 | Val Loss: 1.0273 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.47it/s]\n",
            "Epoch 35/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 35 | Train Loss: 1.0233 | Val Loss: 1.0260 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 36, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -4.613113880157471\n",
            "    Max:  -2.7895052433013916\n",
            "    Mean: -3.788024663925171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 36 | Train Loss: 1.0221 | Val Loss: 1.0239 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.29it/s]\n",
            "Epoch 37/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 37 | Train Loss: 1.0213 | Val Loss: 1.0225 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.28it/s]\n",
            "Epoch 38/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 38 | Train Loss: 1.0198 | Val Loss: 1.0208 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.85it/s]\n",
            "Epoch 39/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 39 | Train Loss: 1.0195 | Val Loss: 1.0202 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.12it/s]\n",
            "Epoch 40/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] Epoch 40 | Train Loss: 1.0185 | Val Loss: 1.0198 | IoU: 1.0000\n",
            "\n",
            "üîÅ Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 1, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -1.667335033416748\n",
            "    Max:  0.7744898200035095\n",
            "    Mean: -0.10266555845737457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 1 | Train Loss: 1.6304 | Val Loss: 1.6856 | IoU: 1.0000\n",
            "‚úÖ Best model saved to saved_models/best_model_fold_2.pth (IoU=1.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.24it/s]\n",
            "Epoch 2/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 2 | Train Loss: 1.4189 | Val Loss: 1.5547 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.18it/s]\n",
            "Epoch 3/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 3 | Train Loss: 1.3193 | Val Loss: 1.3735 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.38it/s]\n",
            "Epoch 4/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 4 | Train Loss: 1.2623 | Val Loss: 1.2550 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.16it/s]\n",
            "Epoch 5/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 5 | Train Loss: 1.2224 | Val Loss: 1.1896 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 6, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.0704104900360107\n",
            "    Max:  -0.8188629150390625\n",
            "    Mean: -1.503871202468872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.41it/s]\n",
            "Epoch 6/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 6 | Train Loss: 1.1932 | Val Loss: 1.1553 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.86it/s]\n",
            "Epoch 7/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 7 | Train Loss: 1.1688 | Val Loss: 1.1332 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.13it/s]\n",
            "Epoch 8/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 8 | Train Loss: 1.1486 | Val Loss: 1.1209 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.19it/s]\n",
            "Epoch 9/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 9 | Train Loss: 1.1318 | Val Loss: 1.1141 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.37it/s]\n",
            "Epoch 10/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 10 | Train Loss: 1.1177 | Val Loss: 1.1057 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 11, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -2.596468448638916\n",
            "    Max:  -1.5297012329101562\n",
            "    Mean: -2.1608099937438965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 11 | Train Loss: 1.1058 | Val Loss: 1.1006 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.05it/s]\n",
            "Epoch 12/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 12 | Train Loss: 1.0955 | Val Loss: 1.1001 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.23it/s]\n",
            "Epoch 13/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 13 | Train Loss: 1.0867 | Val Loss: 1.1021 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.21it/s]\n",
            "Epoch 14/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 14 | Train Loss: 1.0790 | Val Loss: 1.1133 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  5.37it/s]\n",
            "Epoch 15/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 15 | Train Loss: 1.0723 | Val Loss: 1.1377 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 16, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.027567148208618\n",
            "    Max:  -2.0804381370544434\n",
            "    Mean: -2.653106212615967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 16 | Train Loss: 1.0664 | Val Loss: 1.1536 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.15it/s]\n",
            "Epoch 17/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 17 | Train Loss: 1.0613 | Val Loss: 1.1521 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.21it/s]\n",
            "Epoch 18/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 18 | Train Loss: 1.0568 | Val Loss: 1.1374 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.40it/s]\n",
            "Epoch 19/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 19 | Train Loss: 1.0527 | Val Loss: 1.1090 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.18it/s]\n",
            "Epoch 20/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 20 | Train Loss: 1.0491 | Val Loss: 1.0881 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 21, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.4123892784118652\n",
            "    Max:  -2.438033103942871\n",
            "    Mean: -3.0384531021118164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.90it/s]\n",
            "Epoch 21/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 21 | Train Loss: 1.0459 | Val Loss: 1.0742 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.14it/s]\n",
            "Epoch 22/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 22 | Train Loss: 1.0430 | Val Loss: 1.0635 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  4.24it/s]\n",
            "Epoch 23/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 23 | Train Loss: 1.0404 | Val Loss: 1.0555 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.06it/s]\n",
            "Epoch 24/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 24 | Train Loss: 1.0380 | Val Loss: 1.0494 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.18it/s]\n",
            "Epoch 25/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 25 | Train Loss: 1.0358 | Val Loss: 1.0449 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Epoch 26, Batch 1\n",
            "  Predicted mask stats:\n",
            "    Min:  -3.705808639526367\n",
            "    Max:  -2.699151039123535\n",
            "    Mean: -3.3544163703918457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 26 | Train Loss: 1.0338 | Val Loss: 1.0411 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.12it/s]\n",
            "Epoch 27/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 27 | Train Loss: 1.0320 | Val Loss: 1.0378 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/40 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  6.26it/s]\n",
            "Epoch 28/40 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] Epoch 28 | Train Loss: 1.0303 | Val Loss: 1.0352 | IoU: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/40 [Train]:  33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:00<00:00,  3.10it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "## Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset YAML File\n",
        "\n",
        "A YAML (Yet Another Markup Language) file defines the dataset configuration, including paths, classes, and other pertinent details. üòÄ"
      ],
      "metadata": {
        "id": "xE6ntKojSfSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```yaml\n",
        "# Ultralytics üöÄ AGPL-3.0 License - https://ultralytics.com/license\n",
        "\n",
        "# Crack-seg dataset by Ultralytics\n",
        "# Documentation: https://docs.ultralytics.com/datasets/segment/crack-seg/\n",
        "# Example usage: yolo train data=crack-seg.yaml\n",
        "# parent\n",
        "# ‚îú‚îÄ‚îÄ ultralytics\n",
        "# ‚îî‚îÄ‚îÄ datasets\n",
        "#     ‚îî‚îÄ‚îÄ crack-seg  ‚Üê downloads here (91.2 MB)\n",
        "\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: ../datasets/crack-seg # dataset root dir\n",
        "train: train/images # train images (relative to 'path') 3717 images\n",
        "val: valid/images # val images (relative to 'path') 112 images\n",
        "test: test/images # test images (relative to 'path') 200 images\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: crack\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://github.com/ultralytics/assets/releases/download/v0.0.0/crack-seg.zip\n",
        "```"
      ],
      "metadata": {
        "id": "h8go3HNgN0WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n",
        "Train YOLO11 on [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/) datasets. See [YOLO11 Train Docs](https://docs.ultralytics.com/modes/train/) for more information."
      ],
      "metadata": {
        "id": "fMV-sNfiSt_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-seg.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=\"crack-seg.yaml\", epochs=3, imgsz=640, batch=64, workers=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgMYUvlNLvy",
        "outputId": "fd8387d4-b9c9-406c-a7f7-61a28c60d241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.90M/5.90M [00:00<00:00, 99.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.70 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolo11n-seg.pt, data=crack-seg.yaml, epochs=3, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=64, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "\n",
            "Dataset 'crack-seg.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/crack-seg/valid/images'\n",
            "Downloading https://ultralytics.com/assets/crack-seg.zip to '/content/datasets/crack-seg.zip'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 91.1M/91.1M [00:02<00:00, 40.2MB/s]\n",
            "Unzipping /content/datasets/crack-seg.zip to /content/datasets/crack-seg...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8061/8061 [00:01<00:00, 4783.99file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset download success ‚úÖ (5.0s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 41.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    683635  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \n",
            "YOLO11n-seg summary: 355 layers, 2,842,803 parameters, 2,842,787 gradients, 10.4 GFLOPs\n",
            "\n",
            "Transferred 510/561 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/segment/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/crack-seg/train/labels... 3717 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3717/3717 [00:03<00:00, 1105.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/crack-seg/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.3 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/crack-seg/valid/labels... 200 images, 1 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 706.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/crack-seg/valid/labels.cache\n",
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      11.3G      1.349        2.3      2.286      1.316         15        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59/59 [01:34<00:00,  1.61s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.405      0.437      0.361      0.129      0.293      0.317      0.208     0.0421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3      11.3G      1.221      1.656      1.575      1.213          5        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59/59 [01:28<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.484       0.47      0.372      0.162      0.426      0.402      0.247     0.0643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3      11.5G      1.155      1.627      1.323      1.185         11        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59/59 [01:27<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.386      0.481      0.369      0.141      0.267      0.333      0.156     0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.083 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.70 üöÄ Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,834,763 parameters, 0 gradients, 10.2 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        200        249      0.485      0.476      0.371      0.161       0.42      0.398      0.243     0.0637\n",
            "Speed: 0.2ms preprocess, 3.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Dataset sample image](https://github.com/ultralytics/docs/releases/download/0/crack-segmentation-sample.avif)"
      ],
      "metadata": {
        "id": "_Hapx6WkS--T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n",
        "YOLO11 may be used directly in the Command Line Interface (CLI) with a yolo command for a variety of tasks and modes and accepts additional arguments, i.e. imgsz=640. See a full list of available [yolo arguments](https://docs.ultralytics.com/usage/cfg/) and other details in the [YOLO11 Predict Docs](https://docs.ultralytics.com/modes/train/)."
      ],
      "metadata": {
        "id": "mKAUvDAbTEjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/path/to/best.pt\")  # load a fine-tuned model\n",
        "\n",
        "# Inference using the model (img/video/stream)\n",
        "results = model.predict(\"https://github.com/ultralytics/assets/releases/download/v0.0.0/crack-on-wall.jpg\", save=True)"
      ],
      "metadata": {
        "id": "nzTbeqK_TB6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b447bde9-2847-4863-d658-181c78d35258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found https://github.com/ultralytics/assets/releases/download/v0.0.0/crack-on-wall.jpg locally at crack-on-wall.jpg\n",
            "image 1/1 /content/crack-on-wall.jpg: 384x640 1 crack, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://github.com/user-attachments/assets/9044c148-c157-47d6-87b4-5608593f5b70\" width=\"600\">"
      ],
      "metadata": {
        "id": "lmNKY3rWWsvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export\n",
        "\n",
        "Export a YOLO11 model to any supported format below with the `format` argument, i.e. `format=onnx`. See [YOLO11 Export Docs](https://docs.ultralytics.com/modes/export/) for more information.\n",
        "\n",
        "- üí° ProTip: Export to [ONNX](https://docs.ultralytics.com/integrations/onnx/) or [OpenVINO](https://docs.ultralytics.com/integrations/openvino/) for up to 3x CPU speedup.  \n",
        "- üí° ProTip: Export to [TensorRT](https://docs.ultralytics.com/integrations/tensorrt/) for up to 5x GPU speedup.\n",
        "\n",
        "| Format                                                                   | `format` Argument | Model                     | Metadata | Arguments                                                            |\n",
        "|--------------------------------------------------------------------------|-------------------|---------------------------|----------|----------------------------------------------------------------------|\n",
        "| [PyTorch](https://pytorch.org/)                                          | -                 | `yolo11n.pt`              | ‚úÖ        | -                                                                    |\n",
        "| [TorchScript](https://docs.ultralytics.com/integrations/torchscript)     | `torchscript`     | `yolo11n.torchscript`     | ‚úÖ        | `imgsz`, `optimize`, `batch`                                         |\n",
        "| [ONNX](https://docs.ultralytics.com/integrations/onnx)                   | `onnx`            | `yolo11n.onnx`            | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `opset`, `batch`             |\n",
        "| [OpenVINO](https://docs.ultralytics.com/integrations/openvino)           | `openvino`        | `yolo11n_openvino_model/` | ‚úÖ        | `imgsz`, `half`, `dynamic`, `int8`, `batch`                          |\n",
        "| [TensorRT](https://docs.ultralytics.com/integrations/tensorrt)           | `engine`          | `yolo11n.engine`          | ‚úÖ        | `imgsz`, `half`, `dynamic`, `simplify`, `workspace`, `int8`, `batch` |\n",
        "| [CoreML](https://docs.ultralytics.com/integrations/coreml)               | `coreml`          | `yolo11n.mlpackage`       | ‚úÖ        | `imgsz`, `half`, `int8`, `nms`, `batch`                              |\n",
        "| [TF SavedModel](https://docs.ultralytics.com/integrations/tf-savedmodel) | `saved_model`     | `yolo11n_saved_model/`    | ‚úÖ        | `imgsz`, `keras`, `int8`, `batch`                                    |\n",
        "| [TF GraphDef](https://docs.ultralytics.com/integrations/tf-graphdef)     | `pb`              | `yolo11n.pb`              | ‚ùå        | `imgsz`, `batch`                                                     |\n",
        "| [TF Lite](https://docs.ultralytics.com/integrations/tflite)              | `tflite`          | `yolo11n.tflite`          | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [TF Edge TPU](https://docs.ultralytics.com/integrations/edge-tpu)        | `edgetpu`         | `yolo11n_edgetpu.tflite`  | ‚úÖ        | `imgsz`                                                              |\n",
        "| [TF.js](https://docs.ultralytics.com/integrations/tfjs)                  | `tfjs`            | `yolo11n_web_model/`      | ‚úÖ        | `imgsz`, `half`, `int8`, `batch`                                     |\n",
        "| [PaddlePaddle](https://docs.ultralytics.com/integrations/paddlepaddle)   | `paddle`          | `yolo11n_paddle_model/`   | ‚úÖ        | `imgsz`, `batch`                                                     |\n",
        "| [MNN](https://docs.ultralytics.com/integrations/mnn)                     | `mnn`             | `yolo11n.mnn`             | ‚úÖ        | `imgsz`, `batch`, `int8`, `half`                                     |\n",
        "| [NCNN](https://docs.ultralytics.com/integrations/ncnn)                   | `ncnn`            | `yolo11n_ncnn_model/`     | ‚úÖ        | `imgsz`, `half`, `batch`                                             |\n",
        "| [IMX500](https://docs.ultralytics.com/integrations/sony-imx500)          | `imx`             | `yolov8n_imx_model/`      | ‚úÖ        | `imgsz`, `int8`                                                      |\n",
        "| [RKNN](https://docs.ultralytics.com/integrations/rockchip-rknn)          | `rknn`            | `yolo11n_rknn_model/`     | ‚úÖ        | `imgsz`, `batch`, `name`                                             |"
      ],
      "metadata": {
        "id": "vWBYYdXhTkN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"/path/to/best.pt\")  # load a custom trained model\n",
        "\n",
        "# Export the model\n",
        "model.export(format=\"torchscript\")"
      ],
      "metadata": {
        "id": "S4nWG40CTlOD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "c3db12b5-4f21-4c79-eea1-484057f2c7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.70 üöÄ Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "YOLO11n-seg summary (fused): 265 layers, 2,834,763 parameters, 0 gradients, 10.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 37, 8400), (1, 32, 160, 160)) (5.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.5.1+cu124...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 4.8s, saved as '/content/best.torchscript' (11.4 MB)\n",
            "\n",
            "Export complete (5.7s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=segment model=/content/best.torchscript imgsz=640  \n",
            "Validate:        yolo val task=segment model=/content/best.torchscript imgsz=640 data=/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/datasets/crack-seg.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/best.torchscript'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}